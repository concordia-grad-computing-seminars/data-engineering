{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25530833-5467-43f9-abff-aa5f917ee168",
   "metadata": {},
   "source": [
    "# Consumer rating of cereals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5736a264-e908-4bf3-b5be-99c816e64179",
   "metadata": {},
   "source": [
    "![Cereals](img/cereals.jpg \"Some cereals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b5b05d-206a-4e03-b346-85588fbc3b84",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "- Complete as needed this notebook in order to be able to answer the various questions.\n",
    "- Submit on moodle your notebook as well as the PDF or HTML copy of your notebook (with answers computed)\n",
    "- Please submit a clean notebook (i.e. only the code needed to obtain the answers and not including all debugging / trials you did)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61675216-2cee-4020-add6-1d6a0c0ba0a0",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baa3e81-98d6-476a-ac6a-807cc4c741af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764ccbc5-8337-4745-8f01-379ee3740fb6",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6831ccca-af05-41aa-beeb-90206a28a759",
   "metadata": {},
   "source": [
    "Source: https://www.kaggle.com/datasets/crawford/80-cereals\n",
    "\n",
    "```\n",
    "Fields in the dataset:\n",
    "\n",
    "    Name: Name of cereal\n",
    "    mfr: Manufacturer of cereal\n",
    "        A = American Home Food Products;\n",
    "        G = General Mills\n",
    "        K = Kelloggs\n",
    "        N = Nabisco\n",
    "        P = Post\n",
    "        Q = Quaker Oats\n",
    "        R = Ralston Purina \n",
    "    type:\n",
    "        cold\n",
    "        hot \n",
    "    calories: calories per serving\n",
    "    protein: grams of protein\n",
    "    fat: grams of fat\n",
    "    sodium: milligrams of sodium\n",
    "    fiber: grams of dietary fiber\n",
    "    carbo: grams of complex carbohydrates\n",
    "    sugars: grams of sugars\n",
    "    potass: milligrams of potassium\n",
    "    vitamins: vitamins and minerals - 0, 25, or 100, indicating the typical percentage of FDA recommended\n",
    "    shelf: display shelf (1, 2, or 3, counting from the floor)\n",
    "    weight: weight in ounces of one serving\n",
    "    cups: number of cups in one serving\n",
    "    rating: a rating of the cereals\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56b5e63-d7ca-4cf4-bcd4-6e778805d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cereals = pd.read_csv('cereal.csv')\n",
    "cereals.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d333677b-6689-4afc-89e0-f82a18f55988",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6486ce36-8397-4fc0-a73f-f2dde58d1363",
   "metadata": {},
   "source": [
    "## 1. Data preparation\n",
    "\n",
    "In this question we are going to prepare the data for our model training. For this we will remove some features we will not consider and create two classes that will be the target values of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a56e178-eb6a-4e28-b333-4a7215398d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a copy of the original data\n",
    "df = cereals.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0717ef-596d-4aed-b6e0-c5a6c7776fa7",
   "metadata": {},
   "source": [
    "### 1.1. Creation of two classes\n",
    "\n",
    "The histogram below shows the distribution the consumer ratings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb6c848-1c71-4ab1-b3ef-c8cbbc09cd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cereals.rating.hist()\n",
    "plt.xlabel('Consumer ratings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82792f28-3527-4871-9b2f-2329a42d48f5",
   "metadata": {},
   "source": [
    "Create a new column `quality` in your `dataframe` `df` which takes two values: `good` and `poor`.<br>\n",
    "For consumer ratings higher than 40 the value should be `good`, and for the oter cases it should be `low`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fb1bfd-ede7-45f7-a88d-7dee5fd9181e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of your new column\n",
    "df['quality'] = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420cf0c-bf3f-45ae-8b5a-d6371b3cc987",
   "metadata": {},
   "source": [
    "Create a bar plot showing the two classes you created. Are they approximately balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161b7493-676a-453f-915c-09cd5fa25215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of the two classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b180cbf-518c-4742-b04b-018613517d26",
   "metadata": {},
   "source": [
    "### 1.2. Splitting your data in training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640e9e3f-86a6-4dea-b6f6-2feb726c18f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target values\n",
    "y = df.quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a4a445-ad27-4812-a204-ea2a52369cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that are no longer needed at this stage\n",
    "df = df.drop(columns=['name', 'shelf', 'rating', 'quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7e886-0fe6-4be0-a177-15313131e712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in training and test set\n",
    "df_train, df_test, y_train, y_test = train_test_split(df, y,  test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ec390f-3f18-4ddd-8f44-1551b5b764b1",
   "metadata": {},
   "source": [
    "## 2. Numerical features importance estimation using a random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e133a61f-340b-480b-a258-12b716402bcd",
   "metadata": {},
   "source": [
    "In this part we will find which numerical features have the most importance in the predcition of the quality of the product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20175dc-9ff8-4d32-a07a-255b5dc4936e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numerical features we have\n",
    "numeric_features = ['protein', 'fat', 'sodium', 'fiber', 'carbo', 'sugars', 'potass', 'vitamins']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5c57c3-fe73-43e1-9325-e8a743a24d4c",
   "metadata": {},
   "source": [
    "To estimate the importance of these numerical features we train a random forest classifier using these features and then list the features according order of importance.\n",
    "\n",
    "Methodology to follow:\n",
    "- Using cross-validation, fine tune the hyper-parameter `n_estimators`\n",
    "- Train the random forest using the tuned hyper-parameter `n_estimators`\n",
    "- List in order of importance the features using the `feature_importances_` attribute of the trained random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f290fe00-0e34-421c-9d73-e85d36d384da",
   "metadata": {},
   "source": [
    "### 2.1. Random forest hyper-parameter tuning by cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7439f0-b991-4fdc-8538-fd3cd838e6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features matrix\n",
    "X_train = np.c_[df_train.protein, df_train.fat, df_train.sodium, df_train.fiber, df_train.carbo, df_train.sugars, df_train.potass, df_train.vitamins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33efb25a-b2f9-43b2-afc7-548bb499305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82f0919-78e6-4784-a244-447bbdd71c26",
   "metadata": {},
   "source": [
    "### 2.2. Train random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8561ab48-4525-427b-8fe4-680c30a71c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a random forest classifier with the selected hyper-parameter `n_estimators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c87602-b521-4ef2-a09b-1db78e072eef",
   "metadata": {},
   "source": [
    "### 2.3. Display features by importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa054d0-2113-4a40-85d0-4585bcd6d5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features by decreasing order of importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7ae5bc-5687-4e26-8d2a-a9d775659359",
   "metadata": {},
   "source": [
    "### 3. Pre-processing pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70abb84-7d85-4e3d-b09d-16f3c5ed8511",
   "metadata": {},
   "source": [
    "In this question we will create the pipeline to pre-process the data for all coming models.\n",
    "\n",
    "The pipeline handles the numerical features and the categorical features differently:\n",
    "- For all numerical features we apply a `StandardScaler`.\n",
    "- For all categorical features we apply a `OneHotEncoder`.\n",
    "\n",
    "The numerical features to use are the three most important features you have identified in question 2.3.\n",
    "\n",
    "The categorical features are `mfr` and `type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96ba1a8-6870-46d9-af78-c0b835578793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipline to transform the features (StandardScaler for numerical and OneHotEncoder for categorical features)\n",
    "# Use the template below\n",
    "#\n",
    "# Note: The picture below shows and example where the numerical features would be 'fiber', 'potass' and 'sugars'\n",
    "\n",
    "def preProcess():\n",
    "    \"\"\"\n",
    "    Pre-processing pipeline for the data\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4ce1e5-e27c-4333-8bc9-a5d3d1add206",
   "metadata": {},
   "source": [
    "![Pipeline](img/preprocess_pipeline.png \"Visual representation of the pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0adace-6723-40db-85de-61bfb5d8ac6d",
   "metadata": {},
   "source": [
    "## 4. Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b9e6c5-1b2f-480e-933c-f2b21019608a",
   "metadata": {},
   "source": [
    "In this question we train a random forest classifier on our data.\n",
    "\n",
    "Methodology to follow:\n",
    "- Using cross-validation, fine tune the hyper-parameter `n_estimators`\n",
    "- Train the random forest using the tuned hyper-parameter `n_estimators`\n",
    "- Evaluate its performance (Score and confusion matrix) on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2b788b-18ab-494e-a0b6-f111298bdcc8",
   "metadata": {},
   "source": [
    "### 4.1. Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718531de-3074-4143-99dc-39d052c6e751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the training data with your pipeline\n",
    "pip = preProcess()\n",
    "X_train = pip.fit_transform(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae584c2a-2737-4a52-ab7e-81ed3e7ca72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune n_estimators by cross validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c249dd18-011e-4381-9ee8-803d546e79da",
   "metadata": {},
   "source": [
    "### 4.2. Training of a random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab03cad4-4c8a-4146-923e-87e91cac7887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a radnom forest classifier with the selected hyper-parameter n_estimators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48ed4d6-a058-4163-9172-b93d967dab75",
   "metadata": {},
   "source": [
    "### 4.3. Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8d67c9-b2bb-48bd-9aa5-fb05b3d51fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the test data with your pipeline\n",
    "X_test = pip.fit_transform(df_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b64802c-c56b-4005-be49-33905657f88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of your trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e570bacc-6d5b-4711-abab-7ad3fad90791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6eadf8-4c96-4673-82be-d2dcea00a155",
   "metadata": {},
   "source": [
    "## 5. KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855cb697-ae3a-40ec-9233-1e98db26b642",
   "metadata": {},
   "source": [
    "In this question we train a KNN classifier (`KNeighborsClassifier`) on our data.\n",
    "\n",
    "Methodology to follow:\n",
    "- Using cross-validation, fine tune the hyper-parameter `n_neighbors`\n",
    "- Train the KNN model using the tuned hyper-parameter `n_neighbors`\n",
    "- Evaluate its performance (Score and confusion matrix) on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534b2b8b-a94f-4dc0-afd1-8f4354844530",
   "metadata": {},
   "source": [
    "### 5.1. Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40963e93-3197-4189-a93a-5719b282d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the training data with your pipeline\n",
    "pip = preProcess()\n",
    "X_train = pip.fit_transform(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f81aa90-89bd-4a14-9bed-352a97bdfce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine tune n_neighbors by cross validation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36f0410-0df6-4345-87f6-c77a34f71282",
   "metadata": {},
   "source": [
    "### 5.2. Training of a KNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f255f82-a954-4c4a-8b64-d365500ce93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a KNN classifier with the selected hyper-parameter n_neighbors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e821110-a2a9-4e3e-b4f5-4866069daad6",
   "metadata": {},
   "source": [
    "### 5.3. Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44d462d-3067-48dd-88d4-b29dd8dda050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the test data with your pipeline\n",
    "X_test = pip.fit_transform(df_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e26201-a381-405b-abbf-c6fe810ccd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of your trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c6207-d3de-4357-897a-168a999a369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5025a7b5-b6be-4ccf-bdac-1664f308d082",
   "metadata": {},
   "source": [
    "## 6. Logistic regression\n",
    "\n",
    "In this question we train a Logistic Regression classifier (`LogisticRegression`) on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5c5751-d874-43b1-b8bc-541ac5441765",
   "metadata": {},
   "source": [
    "### 6.1. Logistic regression model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a997c8ed-65ca-4262-b53b-33b9a7d078d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the training data with your pipeline\n",
    "pip = preProcess()\n",
    "X_train = pip.fit_transform(df_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ef5894-189c-46e6-997d-2f42f9910aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Logistic Regression classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e4bc05-34cd-4b04-8d71-271695208386",
   "metadata": {},
   "source": [
    "### 6.2. Evaluation on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2c7f0b-0be8-491e-80f6-79eff10a3baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process the test data with your pipeline\n",
    "X_test = pip.fit_transform(df_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b449079f-9827-4c5e-aa58-633956d130d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the accuracy of your trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a8ea4-eefe-4dca-8e52-f8fe5a4c37e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b939d414-7b6a-40ad-afec-70d9cba7c4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SciKit Learn",
   "language": "python",
   "name": "scikit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
